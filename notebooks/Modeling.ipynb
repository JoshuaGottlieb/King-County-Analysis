{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import itertools as itt\n",
    "import pickle as pk\n",
    "\n",
    "full_train = pd.read_parquet('../data/cleaned/all_features_train.parquet')\n",
    "full_test = pd.read_parquet('../data/cleaned/all_features_test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test and train data sets into X, y_norm, and y_log\n",
    "X_train, y_train_norm, y_train_log = (full_train.drop(['price', 'log(price_plus_0)'], axis = 1),\n",
    "                                      full_train.price,\n",
    "                                      full_train['log(price_plus_0)'])\n",
    "X_test, y_test_norm, y_test_log = (full_test.drop(['price', 'log(price_plus_0)'], axis = 1),\n",
    "                                      full_test.price,\n",
    "                                      full_test['log(price_plus_0)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns of zeroes for each column present in X_train but not present in X_test\n",
    "# zipcode_98050 was not present in X_test and was duplicated through one-hot-encoding and engineered interactions\n",
    "# Since all of these columns represent dummy variables, this should not affect modeling whatsoever\n",
    "# X_test and X_train need to have the same shape for sklearn LinearRegression()\n",
    "def equalize_columns(df_1, df_2):\n",
    "    col_to_add_1 = [x for x in df_2.columns if x not in df_1.columns]\n",
    "    col_to_add_2 = [x for x in df_1.columns if x not in df_2.columns]\n",
    "    \n",
    "    if col_to_add_1 != []:\n",
    "        for col in col_to_add_1:\n",
    "            df_1[col] = 0\n",
    "            \n",
    "    if col_to_add_2 != []:\n",
    "        for col in col_to_add_2:\n",
    "            df_2[col] = 0\n",
    "            \n",
    "    df_1_col_order = df_1.columns.values.tolist()\n",
    "    \n",
    "    df_2.reindex(columns = df_1_col_order)\n",
    "    \n",
    "\n",
    "equalize_columns(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs a linear regression fitted on train data, then predicts on test data using a specified column set\n",
    "# Creates a pandas DataFrame containing the R^2 value of X_train, y_train\n",
    "# as well as the R^2 value obtained from predicting on X_test using coefficients from fitting on X_train\n",
    "# Also contains the fitted coefficient names/values/p-scores\n",
    "# Returns the y_prediction from predicting on X_test and the pandas DataFrame with tabular information\n",
    "def run_linear_regression(X_train, y_train, X_test, y_test, column_subset):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train[column_subset], y_train)\n",
    "    lr_sm = sm.OLS(y_train, sm.add_constant(X_train[column_subset])).fit()\n",
    "    \n",
    "    regression_frame = pd.concat([pd.DataFrame(zip(['Test R^2'], [lr.score(X_test[column_subset], y_test)])),\n",
    "                                  pd.DataFrame(zip(['Train R^2'], [lr_sm.rsquared])),\n",
    "                                  lr_sm.params.reset_index().rename(columns = {'index': 0, 0: 1})])\n",
    "    regression_frame['p_values'] = [None, None] + lr_sm.pvalues.values.tolist()\n",
    "    regression_frame.columns = ['param', 'coeff', 'p_values']\n",
    "    \n",
    "    y_pred = lr.predict(X_test[column_subset])\n",
    "    \n",
    "    return y_pred, regression_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks if any string in a given list is a substring of given string\n",
    "def substring_from_list_in_string(list_one, test_string):\n",
    "    for string in list_one:\n",
    "        if string in test_string:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans an array of symmetric interaction terms (a_x_b vs. b_x_a) and returns only unique features\n",
    "def get_unique_interactions(features):\n",
    "    features_unique = []\n",
    "    for feature in features:\n",
    "        if feature in features_unique:\n",
    "            continue\n",
    "        if '_x_' not in feature:\n",
    "            features_unique.append(feature)\n",
    "        else:\n",
    "            split_feature = feature.split('_x_')\n",
    "            split_feature.reverse()\n",
    "            rejoined_feature = '_x_'.join(split_feature)\n",
    "            if rejoined_feature in features_unique:\n",
    "                continue\n",
    "            else:\n",
    "                features_unique.append(feature)\n",
    "            \n",
    "    return features_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining base categories for further selection use\n",
    "binaries = ['waterfront', 'greenbelt', 'nuisance']\n",
    "ordinals = ['view', 'condition', 'grade']\n",
    "discrete = ['bedrooms', 'bathrooms', 'floors', 'yr_built']\n",
    "continuous = [x for x in X_train.columns if 'sqft' in x and '_x_' not in x and 'log' not in x]\n",
    "zipcodes = [x for x in X_train.columns if 'zip' in x and '_x_' not in x]\n",
    "log_continuous = [x for x in X_train.columns if 'log' in x and '_x_' not in x]\n",
    "ordinal_ohes = [x for x in X_train.columns if ('view' in x or 'condition' in x or 'grade' in x)\\\n",
    "                and '_' in x and '_x_' not in x]\n",
    "ohes = [x for x in X_train.columns if '_' in x and '_x_' not in x\\\n",
    "        and x not in set(itt.chain(binaries, ordinals, discrete, continuous,\\\n",
    "                                   log_continuous, zipcodes, ordinal_ohes))]\n",
    "interactions = [x for x in X_train.columns if '_x_' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Testing that the shape and values of base categories matches all column values in X_train\n",
    "# In other words, the above lists partition all of X_train\n",
    "print(len(X_train.columns.values) == len(set(binaries + ordinals + discrete\\\n",
    "                                        + continuous + zipcodes + log_continuous\\\n",
    "                                        + ordinal_ohes + ohes + interactions)),\n",
    "      set(X_train.columns.values) == set(binaries + ordinals + discrete\\\n",
    "                                   + continuous + zipcodes + log_continuous\\\n",
    "                                   + ordinal_ohes + ohes + interactions),\n",
    "      sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param</th>\n",
       "      <th>coeff</th>\n",
       "      <th>p_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test R^2</td>\n",
       "      <td>0.443392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train R^2</td>\n",
       "      <td>0.420277</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       param     coeff  p_values\n",
       "0   Test R^2  0.443392       NaN\n",
       "0  Train R^2  0.420277       NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple linear regression on highest correlated column - sqft_living\n",
    "# Test R^2 of 0.4434 is not very strong\n",
    "simple_columns = ['sqft_living']\n",
    "y_pred, df = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, simple_columns)\n",
    "df.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.751223       NaN\n",
      "0  Train R^2  0.757472       NaN\n",
      "\n",
      "       param     coeff  p_values\n",
      "0   Test R^2  0.726913       NaN\n",
      "0  Train R^2  0.719369       NaN\n"
     ]
    }
   ],
   "source": [
    "# Create multi-linear regression baseline using all of the base categories\n",
    "# Except: continuous variables not log transformed and ordinal variables encoded ordinally instead of as ohe\n",
    "# Much better Test R^2: 0.7512\n",
    "baseline_columns = binaries + ordinals + discrete + continuous + zipcodes + ohes\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, baseline_columns)\n",
    "\n",
    "# Test baseline regression using log-transformed y (price)\n",
    "# Test R^2 slightly worse, 0.7269\n",
    "y_pred_2, df_2 = run_linear_regression(X_train, y_train_log, X_test, y_test_log, baseline_columns)\n",
    "\n",
    "# Write y_pred and df to pickle objects for use in visualizations\n",
    "# with open('../data/cleaned/baseline_regression_y_pred.pickle', 'wb') as f:\n",
    "#     pk.dump(y_pred, f)\n",
    "# with open('../data/cleaned/baseline_regression_coeff_frame.pickle', 'wb') as f:\n",
    "#     pk.dump(df, f)\n",
    "\n",
    "print(df_1.iloc[:2], df_2.iloc[:2], sep = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.729757       NaN\n",
      "0  Train R^2  0.736595       NaN\n",
      "\n",
      "       param     coeff  p_values\n",
      "0   Test R^2  0.728624       NaN\n",
      "0  Train R^2  0.720479       NaN\n"
     ]
    }
   ],
   "source": [
    "# Test variation of baseline regression using log-transformed continuous variables\n",
    "# Test R^2 against norm y: 0.7298, Test R^2 against log y: 0.7286, roughly equal but worse than baseline\n",
    "baseline_log_cont = binaries + ordinals + discrete + log_continuous + zipcodes + ohes\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, baseline_log_cont)\n",
    "y_pred_2, df_2 = run_linear_regression(X_train, y_train_log, X_test, y_test_log, baseline_log_cont)\n",
    "\n",
    "print(df_1.iloc[:2], df_2.iloc[:2], sep = '\\n\\n')\n",
    "\n",
    "# # Write y_pred_2 and df_2 to pickle objects for use in visualizations\n",
    "# with open('../data/cleaned/log_continuous_y_pred_on_test.pickle', 'wb') as f:\n",
    "#     pk.dump(y_pred_2, f)\n",
    "# with open('../data/cleaned/log_continuous_coeff_frame.pickle', 'wb') as f:\n",
    "#     pk.dump(df_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.753132       NaN\n",
      "0  Train R^2  0.761993       NaN\n",
      "\n",
      "       param     coeff  p_values\n",
      "0   Test R^2  0.727410       NaN\n",
      "0  Train R^2  0.720576       NaN\n"
     ]
    }
   ],
   "source": [
    "# Test converting all ordinal columns except for grade to one-hot-encoded columns\n",
    "# Performance not greatly improved over baseline model\n",
    "ordinals_not_grade = [x for x in ordinals if 'grade' not in x]\n",
    "ordinals_ohe_not_grade = [x for x in ordinal_ohes if 'grade' not in x]\n",
    "X_col = list(set(baseline_columns) - set(ordinals_not_grade)) + ordinals_ohe_not_grade\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, X_col)\n",
    "y_pred_2, df_2 = run_linear_regression(X_train, y_train_log, X_test, y_test_log, X_col)\n",
    "print(df_1.iloc[:2], df_2.iloc[:2], sep = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.732101       NaN\n",
      "0  Train R^2  0.741420       NaN\n",
      "\n",
      "       param     coeff  p_values\n",
      "0   Test R^2  0.729217       NaN\n",
      "0  Train R^2  0.721780       NaN\n"
     ]
    }
   ],
   "source": [
    "# Same test as above but with log-transformed continuous variables\n",
    "# Worse performance than before\n",
    "X_col = list(set(baseline_log_cont) - set(ordinals_not_grade)) + ordinals_ohe_not_grade\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, X_col)\n",
    "y_pred_2, df_2 = run_linear_regression(X_train, y_train_log, X_test, y_test_log, X_col)\n",
    "print(df_1.iloc[:2], df_2.iloc[:2], sep = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.788337       NaN\n",
      "0  Train R^2  0.824724       NaN\n",
      "\n",
      "       param     coeff  p_values\n",
      "0   Test R^2  0.727210       NaN\n",
      "0  Train R^2  0.742562       NaN\n"
     ]
    }
   ],
   "source": [
    "# Zip code appeared to greatly affect all other independent variabels during EDA\n",
    "# Test using zip interaction columns between binary and continuous variables\n",
    "# Test R^2 against y norm: 0.7883, an improvement over the baseline model\n",
    "# Test R^2 against y log has consistently performed worse compared to y norm, not worth calculating moving forward\n",
    "binaries_and_continuous = binaries + continuous\n",
    "zip_interactions_bc = [x for x in interactions if substring_from_list_in_string(binaries_and_continuous, x)\\\n",
    "                    and substring_from_list_in_string(zipcodes, x)\\\n",
    "                    and 'log' not in x]\n",
    "X_col = baseline_columns + zip_interactions_bc\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, X_col)\n",
    "y_pred_2, df_2 = run_linear_regression(X_train, y_train_log, X_test, y_test_log, X_col)\n",
    "print(df_1.iloc[:2], df_2.iloc[:2], sep = '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.784441       NaN\n",
      "0  Train R^2  0.849847       NaN\n"
     ]
    }
   ],
   "source": [
    "# Test using all zipcode interactions with baseline variables\n",
    "# Test R^2 of 0.7844, worse than prior model\n",
    "zipcode_interactions_baseline = [x for x in interactions if substring_from_list_in_string(baseline_columns, x)\\\n",
    "                    and substring_from_list_in_string(zipcodes, x)\\\n",
    "                    and not substring_from_list_in_string(ordinal_ohes, x)\n",
    "                    and 'log' not in x]\n",
    "X_col = get_unique_interactions(baseline_columns + zipcode_interactions_baseline)\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, X_col)\n",
    "print(df_1.iloc[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.795226       NaN\n",
      "0  Train R^2  0.831509       NaN\n"
     ]
    }
   ],
   "source": [
    "# Try looking at numerical interactions containing at least one continuous or discrete feature\n",
    "# This includes zipcode interactions involving continuous or discrete features\n",
    "# Have to use get_unique_interactions to remove symmetrically selected interaction features\n",
    "# Test R^2 on norm y: 0.7952, an improvement on all prior models!\n",
    "cont_and_disc = continuous + discrete\n",
    "numerical_interactions = [x for x in interactions if substring_from_list_in_string(cont_and_disc, x)\\\n",
    "                          and not substring_from_list_in_string(ordinal_ohes, x)\\\n",
    "                          and 'log' not in x]\n",
    "X_col = get_unique_interactions(baseline_columns + numerical_interactions)\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, X_col)\n",
    "print(df_1.iloc[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.789665       NaN\n",
      "0  Train R^2  0.847317       NaN\n"
     ]
    }
   ],
   "source": [
    "# Test using one-hot encoding for ordinal variables\n",
    "# Test R^2 = 0.7900, good, but not as good as previous\n",
    "baseline_ordohe = discrete + continuous + binaries + ordinal_ohes + ohes + zipcodes\n",
    "zipcode_interactions_baseline_ordohe = [x for x in interactions if substring_from_list_in_string(baseline_ordohe, x)\\\n",
    "                    and substring_from_list_in_string(zipcodes, x)\\\n",
    "                    and not substring_from_list_in_string(ordinals, x)\n",
    "                    and 'log' not in x]\n",
    "X_col = get_unique_interactions(baseline_ordohe + zipcode_interactions_baseline_ordohe)\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, X_col)\n",
    "print(df_1.iloc[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.790791       NaN\n",
      "0  Train R^2  0.848229       NaN\n"
     ]
    }
   ],
   "source": [
    "# Same test as above but with log-transformed continuous variables\n",
    "# Test R^2 = 0.7908, still not as good as using numerical interactions\n",
    "log_base_ordohe = discrete + log_continuous + binaries + ordinal_ohes + ohes + zipcodes\n",
    "zipcode_interactions_log_base_ordohe = [x for x in interactions if substring_from_list_in_string(log_base_ordohe, x)\\\n",
    "                    and substring_from_list_in_string(zipcodes, x)\\\n",
    "                    and not substring_from_list_in_string(ordinals, x)\n",
    "                    and 'log' not in x]\n",
    "X_col = get_unique_interactions(log_base_ordohe + zipcode_interactions_log_base_ordohe)\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, X_col)\n",
    "print(df_1.iloc[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try looking at only sqft_living and sqft_lot, as all other sqft categories are correlated\n",
    "primary_sqft = ['sqft_living', 'sqft_lot']\n",
    "primary_log_sqft = [x for x in log_continuous if substring_from_list_in_string(primary_sqft, x)]\n",
    "primary_base = binaries + ordinals + discrete + primary_sqft + zipcodes + ohes\n",
    "log_continuous_not_primary = [x for x in log_continuous if x not in primary_log_sqft]\n",
    "log_primary_base = binaries + ordinals + discrete + primary_log_sqft + zipcodes + ohes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.801962       NaN\n",
      "0  Train R^2  0.822836       NaN\n"
     ]
    }
   ],
   "source": [
    "# Look at primary base with interactions containing at least one feature from primary_sqft or discrete\n",
    "# Test R^2 = 0.8020, best result so far\n",
    "prim_and_disc = primary_sqft + discrete\n",
    "interactions_prim_disc = [x for x in interactions if substring_from_list_in_string(prim_and_disc, x)\\\n",
    "                          and not substring_from_list_in_string(ordinal_ohes, x)\\\n",
    "                          and 'log' not in x]\n",
    "X_col = get_unique_interactions(primary_base + interactions_prim_disc)\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, X_col)\n",
    "print(df_1.iloc[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       param     coeff  p_values\n",
      "0   Test R^2  0.798162       NaN\n",
      "0  Train R^2  0.816124       NaN\n"
     ]
    }
   ],
   "source": [
    "# Try the same as above but using log-transformed variables\n",
    "# Test R^2 = 0.7982, not bad, but not better than previous\n",
    "log_prim_and_disc = primary_log_sqft + discrete\n",
    "int_log = [x for x in interactions if substring_from_list_in_string(primary_log_sqft, x)\\\n",
    "          and not substring_from_list_in_string(ordinal_ohes, x)]\n",
    "int_disc = [x for x in interactions if substring_from_list_in_string(discrete, x)\\\n",
    "          and not substring_from_list_in_string(ordinal_ohes, x)\\\n",
    "           and not substring_from_list_in_string(continuous, x)\\\n",
    "           and not substring_from_list_in_string(log_continuous_not_primary, x)]\n",
    "X_col = get_unique_interactions(log_primary_base + int_log + int_disc)\n",
    "y_pred_1, df_1 = run_linear_regression(X_train, y_train_norm, X_test, y_test_norm, X_col)\n",
    "print(df_1.iloc[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
